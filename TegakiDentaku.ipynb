{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from PIL import ImageOps\nfrom sklearn.metrics import classification_report, accuracy_score\n\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport PIL.Image as Image\nimport pandas as pd\nimport cv2\nimport time\nimport copy\nimport math\n\n\n\nimport torch\nimport torchvision\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\n\nfrom torchvision import transforms, utils\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split, Subset\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\n\nfrom tqdm import tqdm, notebook","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-10T08:53:38.504041Z","iopub.execute_input":"2021-08-10T08:53:38.504406Z","iopub.status.idle":"2021-08-10T08:53:39.979258Z","shell.execute_reply.started":"2021-08-10T08:53:38.504331Z","shell.execute_reply":"2021-08-10T08:53:39.978363Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"use_gpu = torch.cuda.is_available()\nif use_gpu:\n    print(\"Using CUDA\")","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:53:39.982580Z","iopub.execute_input":"2021-08-10T08:53:39.982832Z","iopub.status.idle":"2021-08-10T08:53:40.043006Z","shell.execute_reply.started":"2021-08-10T08:53:39.982806Z","shell.execute_reply":"2021-08-10T08:53:40.042161Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using CUDA\n","output_type":"stream"}]},{"cell_type":"code","source":"data_set = ImageFolder('/kaggle/input/handwrittendata/digit',\n                        transform=transforms.Compose([\n                            transforms.Resize(28),\n                            transforms.Grayscale(num_output_channels=1),\n                            transforms.ToTensor(),\n                            transforms.Normalize((1, ), (-1, ))],\n                        )\n                      )\nclass_names = data_set.classes[:]\nprint(class_names)\nprint(len(class_names))","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:53:40.046694Z","iopub.execute_input":"2021-08-10T08:53:40.047303Z","iopub.status.idle":"2021-08-10T08:58:39.007899Z","shell.execute_reply.started":"2021-08-10T08:53:40.047274Z","shell.execute_reply":"2021-08-10T08:58:39.006967Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'div', 'equal', 'minus', 'plus', 'times']\n15\n","output_type":"stream"}]},{"cell_type":"code","source":"train_size = int(0.6 * len(data_set))\nval_size = int(0.2 * len(data_set))\ntest_size = len(data_set) - train_size - val_size\ntrain_set, val_set, test_set = random_split(data_set, [train_size, val_size, test_size])\n\ntrain_loader = DataLoader(train_set, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_set, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:58:39.010494Z","iopub.execute_input":"2021-08-10T08:58:39.010883Z","iopub.status.idle":"2021-08-10T08:58:39.047455Z","shell.execute_reply.started":"2021-08-10T08:58:39.010845Z","shell.execute_reply":"2021-08-10T08:58:39.046591Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):    \n    def __init__(self):\n        super(Net, self).__init__()\n          \n        self.features = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n          \n        self.classifier = nn.Sequential(\n            nn.Dropout(p = 0.5),\n            nn.Linear(64 * 7 * 7, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p = 0.5),\n            nn.Linear(512, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p = 0.5),\n            nn.Linear(512, len(class_names)),\n        )\n          \n        for m in self.features.children():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n        \n        for m in self.classifier.children():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n            elif isinstance(m, nn.BatchNorm1d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n                \n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        \n        return x  \n    \n    def load(self, model_path):\n        self.load_state_dict(torch.load(model_path))\n        self.eval()\n\n    def predict(self, images):\n        outputs = self(images)\n        _, predicted = torch.max(outputs, 1)\n        return predicted","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:58:39.048822Z","iopub.execute_input":"2021-08-10T08:58:39.049154Z","iopub.status.idle":"2021-08-10T08:58:39.068594Z","shell.execute_reply.started":"2021-08-10T08:58:39.049119Z","shell.execute_reply":"2021-08-10T08:58:39.067414Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model = Net()\n\noptimizer_ft = optim.Adam(model.parameters(), lr=0.003)\n\ncriterion = nn.CrossEntropyLoss()\n\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:58:39.069947Z","iopub.execute_input":"2021-08-10T08:58:39.070318Z","iopub.status.idle":"2021-08-10T08:58:43.822309Z","shell.execute_reply.started":"2021-08-10T08:58:39.070280Z","shell.execute_reply":"2021-08-10T08:58:43.821280Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    avg_loss = 0\n    avg_acc = 0\n    avg_loss_val = 0\n    avg_acc_val = 0\n    \n    train_batches = len(train_loader)\n    val_batches = len(val_loader)\n    \n    for epoch in range(num_epochs):\n        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n        print('-' * 10)\n        \n        loss_train = 0\n        loss_val = 0\n        acc_train = 0\n        acc_val = 0\n        \n        loss_hist = {'train': [], 'val': []}\n        acc_hist = {'train': [], 'val': []}\n        \n        model.train(True)\n        \n        for i, data in enumerate(train_loader):\n   \n            print(\"\\rTraining batch {}/{}\".format(i, train_batches), end='', flush=True)\n                \n            inputs, labels = data\n            \n            if use_gpu:\n                inputs, labels = inputs.cuda(), labels.cuda()\n            else:\n                pass\n            \n            optimizer.zero_grad()\n            \n            outputs = model(inputs)\n            \n            _, preds = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            \n            loss.backward()\n            optimizer.step()\n            \n            loss_train += loss.data\n            acc_train += torch.sum(preds == labels.data)\n            \n            del inputs, labels, outputs, preds\n            torch.cuda.empty_cache()\n        \n        print()\n        \n        avg_loss = loss_train / len(train_set)\n        avg_acc = acc_train / len(train_set)\n        \n        loss_hist['train'].append(avg_loss)\n        acc_hist['train'].append(avg_acc)\n        \n        model.train(False)\n        model.eval()\n        with torch.no_grad():    \n            for i, data in enumerate(val_loader):\n\n                print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n\n                inputs, labels = data\n\n                if use_gpu:\n                    inputs, labels = inputs.cuda(), labels.cuda()\n                else:\n                    pass\n\n                outputs = model(inputs)\n\n                _, preds = torch.max(outputs.data, 1)\n                loss = criterion(outputs, labels)\n\n                loss_val += loss.data\n                acc_val += torch.sum(preds == labels.data)\n\n                del inputs, labels, outputs, preds\n                torch.cuda.empty_cache()\n\n            avg_loss_val = loss_val / len(val_set)\n            avg_acc_val = acc_val / len(val_set)\n            \n            loss_hist['val'].append(avg_loss)\n            acc_hist['val'].append(avg_acc)\n\n            print()\n            print(\"Epoch {} result: \".format(epoch+1))\n            print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n            print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n            print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n            print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n            print('-' * 10)\n            print()\n\n            if avg_acc_val > best_acc:\n                best_acc = avg_acc_val\n                best_model_wts = copy.deepcopy(model.state_dict())\n        \n    elapsed_time = time.time() - since\n    print()\n    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n    print(\"Best acc: {:.4f}\".format(best_acc))\n    \n    model.load_state_dict(best_model_wts)\n    return model, loss_hist, acc_hist","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:58:43.823781Z","iopub.execute_input":"2021-08-10T08:58:43.824334Z","iopub.status.idle":"2021-08-10T08:58:43.850255Z","shell.execute_reply.started":"2021-08-10T08:58:43.824296Z","shell.execute_reply":"2021-08-10T08:58:43.849493Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model, loss_hist, acc_hist = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)\ntorch.save(model.state_dict(), 'model_v3.pt')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:58:43.852670Z","iopub.execute_input":"2021-08-10T08:58:43.853248Z","iopub.status.idle":"2021-08-10T09:30:14.548072Z","shell.execute_reply.started":"2021-08-10T08:58:43.853209Z","shell.execute_reply":"2021-08-10T09:30:14.547247Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 0/5\n----------\nTraining batch 1599/1600\nValidation batch 533/534\nEpoch 1 result: \nAvg loss (train): 0.0023\nAvg acc (train): 0.9599\nAvg loss (val): 0.0005\nAvg acc (val): 0.9924\n----------\n\nEpoch 1/5\n----------\nTraining batch 1599/1600\nValidation batch 533/534\nEpoch 2 result: \nAvg loss (train): 0.0010\nAvg acc (train): 0.9841\nAvg loss (val): 0.0004\nAvg acc (val): 0.9940\n----------\n\nEpoch 2/5\n----------\nTraining batch 1599/1600\nValidation batch 533/534\nEpoch 3 result: \nAvg loss (train): 0.0008\nAvg acc (train): 0.9877\nAvg loss (val): 0.0003\nAvg acc (val): 0.9956\n----------\n\nEpoch 3/5\n----------\nTraining batch 1599/1600\nValidation batch 533/534\nEpoch 4 result: \nAvg loss (train): 0.0006\nAvg acc (train): 0.9898\nAvg loss (val): 0.0004\nAvg acc (val): 0.9948\n----------\n\nEpoch 4/5\n----------\nTraining batch 1599/1600\nValidation batch 533/534\nEpoch 5 result: \nAvg loss (train): 0.0006\nAvg acc (train): 0.9910\nAvg loss (val): 0.0003\nAvg acc (val): 0.9966\n----------\n\n\nTraining completed in 31m 31s\nBest acc: 0.9966\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred_list = []\ny_true_list = []\nwith torch.no_grad():\n    for x_batch, y_batch in tqdm(test_loader):\n        x_batch, y_batch = x_batch.cuda(), y_batch.cuda()\n        y_test_pred = model(x_batch)\n        _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n        y_pred_list.append(y_pred_tag.cpu().numpy())\n        y_true_list.append(y_batch.cpu().numpy())\n        \ny_pred_list = [i[0] for i in y_pred_list]\ny_true_list = [i[0] for i in y_true_list]","metadata":{"execution":{"iopub.status.busy":"2021-08-10T09:30:14.549586Z","iopub.execute_input":"2021-08-10T09:30:14.549930Z","iopub.status.idle":"2021-08-10T09:34:00.940158Z","shell.execute_reply.started":"2021-08-10T09:30:14.549892Z","shell.execute_reply":"2021-08-10T09:34:00.939155Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"100%|██████████| 534/534 [03:46<00:00,  2.36it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(classification_report(y_true_list, y_pred_list))\nprint(confusion_matrix(y_true_list, y_pred_list))","metadata":{"execution":{"iopub.status.busy":"2021-08-10T09:34:00.941599Z","iopub.execute_input":"2021-08-10T09:34:00.941966Z","iopub.status.idle":"2021-08-10T09:34:01.810773Z","shell.execute_reply.started":"2021-08-10T09:34:00.941924Z","shell.execute_reply":"2021-08-10T09:34:01.809866Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        23\n           1       1.00      0.99      0.99        84\n           2       1.00      1.00      1.00        82\n           3       1.00      1.00      1.00        36\n           4       0.95      1.00      0.98        20\n           5       1.00      1.00      1.00         9\n           6       1.00      1.00      1.00         6\n           7       1.00      1.00      1.00         5\n           8       1.00      1.00      1.00        10\n           9       1.00      1.00      1.00         6\n          10       1.00      1.00      1.00         1\n          11       1.00      1.00      1.00        46\n          12       1.00      0.99      1.00       109\n          13       1.00      1.00      1.00        88\n          14       0.90      1.00      0.95         9\n\n    accuracy                           1.00       534\n   macro avg       0.99      1.00      0.99       534\nweighted avg       1.00      1.00      1.00       534\n\n","output_type":"stream"}]}]}